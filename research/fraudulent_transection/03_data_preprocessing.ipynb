{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tapankheni/Data_Science/Data Science Projects/Credit_Card_Fault_Prediction'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: List[str]\n",
    "    preprocessed_data_path: List[str]\n",
    "    preprocessor_name: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CreditCardFraudDetection.constants import (PARAMS_YAML_FILE_PATH, CONFIG_YAML_FILE_PATH, SCHEMA_YAML_FILE_PATH)\n",
    "from CreditCardFraudDetection.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self,\n",
    "                 params_yaml_file_path = PARAMS_YAML_FILE_PATH,\n",
    "                 config_yaml_file_path = CONFIG_YAML_FILE_PATH,\n",
    "                 schema_yaml_file_path = SCHEMA_YAML_FILE_PATH):\n",
    "\n",
    "        print(params_yaml_file_path) \n",
    "        self.params = read_yaml(params_yaml_file_path)\n",
    "        self.config = read_yaml(config_yaml_file_path)\n",
    "        self.schema = read_yaml(schema_yaml_file_path)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            data_path = config.data_path,\n",
    "            preprocessed_data_path = config.preprocessed_data_path,\n",
    "            preprocessor_name = config.preprocessor_name\n",
    "        )\n",
    "\n",
    "        return data_transformation_config     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CreditCardFraudDetection import logger\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def split_data(self, data: pd.DataFrame, stratify_column: str):\n",
    "        train_data, test_data = train_test_split(data, stratify=data[stratify_column], test_size = 0.3, random_state = 42)\n",
    "        logger.info(\"Data split into train and test sets successfully!\")\n",
    "\n",
    "        X_train, y_train, X_test, y_test = train_data.drop(stratify_column, axis=1), train_data[stratify_column], test_data.drop(stratify_column, axis=1), test_data[stratify_column]\n",
    "        logger.info(\"Features and target variable retrieved successfully!\")\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def get_skewed_features(self, data: pd.DataFrame) -> List[str]:\n",
    "        skewed_features = []\n",
    "\n",
    "        for col in data.select_dtypes(include=[np.number]).columns:\n",
    "            mean = data[col].mean()\n",
    "            median = data[col].median()\n",
    "            mode = data[col].mode().iloc[0]\n",
    "\n",
    "            if mean > median > mode:\n",
    "                skewed_features.append(col)\n",
    "            elif mean < median < mode:\n",
    "                skewed_features.append(col)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        logger.info(f\"Skewed features: {skewed_features}\")\n",
    "\n",
    "        return skewed_features\n",
    "    \n",
    "    def get_preprocessor(self, data: pd.DataFrame) -> Pipeline:\n",
    "        non_skewed_features = list(data.columns)\n",
    "        skewed_features = self.get_skewed_features(data)\n",
    "        non_skewed_features = [col for col in non_skewed_features if col not in skewed_features]\n",
    "        logger.info(f\"Non-skewed features: {non_skewed_features}\")\n",
    "\n",
    "        power_transformation = PowerTransformer(method=\"yeo-johnson\", copy=False, standardize=True)\n",
    "        standard_scaler = StandardScaler()\n",
    "\n",
    "        power_pipeline = Pipeline(\n",
    "            steps=[\n",
    "                (\"power_transformation\", power_transformation)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        numeric_pipeline = Pipeline(\n",
    "            steps=[\n",
    "                (\"scaler\", standard_scaler)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "                (\"power_pipeline\", power_pipeline, skewed_features),\n",
    "                (\"numeric_pipeline\", numeric_pipeline, non_skewed_features),\n",
    "            ],\n",
    "            remainder='passthrough'\n",
    "        )\n",
    "        logger.info(\"Preprocessor created successfully!\")\n",
    "\n",
    "        return preprocessor\n",
    "\n",
    "    def perform_data_transformation(self):\n",
    "        logger.info(\"Starting data transformation...\")\n",
    "\n",
    "        data_path = self.config.data_path[0]\n",
    "\n",
    "        data = pd.read_csv(data_path)\n",
    "        logger.info(f\"Data loaded successfully from {data_path}\")\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = self.split_data(data, 'Class') \n",
    "        logger.info(\"Data split into train and test sets retrieved successfully!\")\n",
    "\n",
    "        preprocessor = self.get_preprocessor(X_train)\n",
    "        logger.info(\"Preprocessor retrieved successfully!\")\n",
    "\n",
    "        logger.info(f\"Before transformation: \\n{X_train.head()}\")\n",
    "\n",
    "        X_train = preprocessor.fit_transform(X_train)\n",
    "        X_test = preprocessor.transform(X_test)\n",
    "\n",
    "        logger.info(f\"After transformation: \\n{X_train[:5]}\")\n",
    "\n",
    "        y_train = y_train.to_numpy()\n",
    "        y_test = y_test.to_numpy()\n",
    "\n",
    "        preprocessed_data_path = self.config.preprocessed_data_path[0]\n",
    "        if not os.path.exists(preprocessed_data_path):\n",
    "            os.makedirs(preprocessed_data_path, exist_ok=True)\n",
    "\n",
    "        np.save(os.path.join(preprocessed_data_path, \"X_train.npy\"), X_train)\n",
    "        np.save(os.path.join(preprocessed_data_path, \"X_test.npy\"), X_test)\n",
    "        np.save(os.path.join(preprocessed_data_path, \"y_train.npy\"), y_train)\n",
    "        np.save(os.path.join(preprocessed_data_path, \"y_test.npy\"), y_test)\n",
    "\n",
    "        logger.info(\"Data saved successfully!\")\n",
    "\n",
    "        joblib.dump(preprocessor, os.path.join(preprocessed_data_path, self.config.preprocessor_name))\n",
    "        logger.info(\"Preprocessor saved successfully!\")\n",
    "\n",
    "        logger.info(\"Data transformation completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params.yaml\n",
      "[2024-07-05 16:29:16,949: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-07-05 16:29:16,952: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-07-05 16:29:16,956: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2024-07-05 16:29:16,957: INFO: common: created directory at: artifacts]\n",
      "[2024-07-05 16:29:16,958: INFO: common: created directory at: artifacts/data_transformation]\n",
      "[2024-07-05 16:29:16,959: INFO: 307610398: Starting data transformation...]\n",
      "[2024-07-05 16:29:18,528: INFO: 307610398: Data loaded successfully from artifacts/data_ingestion/creditcard.csv]\n",
      "[2024-07-05 16:29:18,675: INFO: 307610398: Data split into train and test sets successfully!]\n",
      "[2024-07-05 16:29:18,692: INFO: 307610398: Features and target variable retrieved successfully!]\n",
      "[2024-07-05 16:29:18,694: INFO: 307610398: Data split into train and test sets retrieved successfully!]\n",
      "[2024-07-05 16:29:19,334: INFO: 307610398: Skewed features: ['V1', 'V6', 'V8', 'V9', 'V15', 'V19', 'V20', 'V22', 'V26', 'Amount']]\n",
      "[2024-07-05 16:29:19,335: INFO: 307610398: Non-skewed features: ['V2', 'V3', 'V4', 'V5', 'V7', 'V10', 'V11', 'V12', 'V13', 'V14', 'V16', 'V17', 'V18', 'V21', 'V23', 'V24', 'V25', 'V27', 'V28']]\n",
      "[2024-07-05 16:29:19,335: INFO: 307610398: Preprocessor created successfully!]\n",
      "[2024-07-05 16:29:19,335: INFO: 307610398: Preprocessor retrieved successfully!]\n",
      "[2024-07-05 16:29:19,339: INFO: 307610398: Before transformation: \n",
      "              V1        V2        V3        V4        V5        V6        V7  \\\n",
      "392709 -2.572722  3.246777 -2.461902  1.273214 -3.192952 -2.846110 -2.417016   \n",
      "98663   0.942476 -0.348557  0.571698 -0.169292  0.238363  0.250394  0.492863   \n",
      "534893 -1.558594  1.402685 -1.489328  1.795063 -1.817549 -1.161218 -1.842518   \n",
      "393767 -0.837075  0.511300 -0.567886  0.589584 -0.436640 -0.164560 -0.715996   \n",
      "406053  0.307561  0.677866 -0.803519  1.217240  0.992327 -1.239190  0.107995   \n",
      "\n",
      "              V8        V9       V10  ...       V20       V21       V22  \\\n",
      "392709  5.634254 -1.069645 -1.180863  ...  1.485976  0.572831 -1.826026   \n",
      "98663  -0.146203  0.284062  0.696635  ... -0.381243 -0.080027  0.103488   \n",
      "534893  1.072752 -1.903158 -1.857364  ... -0.342422  0.344495 -0.366975   \n",
      "393767 -0.072717 -0.648623 -0.809593  ... -0.387684  0.867852 -0.086603   \n",
      "406053 -0.133064 -0.784690 -0.797074  ...  0.349460 -0.001169 -0.563997   \n",
      "\n",
      "             V23       V24       V25       V26       V27       V28    Amount  \n",
      "392709 -1.302264  0.376341  3.614986 -0.486587  1.559382  0.802415   1940.67  \n",
      "98663  -0.070464  0.431460  0.863505 -0.816629 -0.227089 -0.088429  11779.89  \n",
      "534893  0.419928  1.388057 -0.677192 -0.831181 -1.137073 -0.708668  19110.45  \n",
      "393767 -0.313272 -0.139820 -0.814056 -0.630577  0.065490  0.301277  12470.67  \n",
      "406053 -0.648798 -0.975296  2.680817  1.126936  0.567807  0.991805   5074.70  \n",
      "\n",
      "[5 rows x 29 columns]]\n",
      "[2024-07-05 16:29:21,852: INFO: 307610398: After transformation: \n",
      "[[-2.55181775e+00 -2.70278452e+00  5.26546379e+00 -1.07019846e+00\n",
      "  -1.79630828e-01  3.36066597e-01  1.48639924e+00 -1.84875993e+00\n",
      "  -4.87045286e-01 -1.57369156e+00  3.24358704e+00 -2.46328184e+00\n",
      "   1.27357481e+00 -3.19724602e+00 -2.52799318e+00 -1.18359646e+00\n",
      "   9.09906196e-01 -8.74656260e-01  1.36607046e+00 -6.48050547e-01\n",
      "  -1.07448486e+00 -1.30722258e+00 -1.41009420e+00  5.73728006e-01\n",
      "  -1.30901665e+00  3.75926502e-01  3.61590672e+00  1.57794637e+00\n",
      "   8.01808255e-01]\n",
      " [ 9.41544476e-01  2.27088086e-01 -1.31804962e-01  2.81379709e-01\n",
      "   3.57557554e-01 -6.36037560e-01 -3.78807776e-01  1.10984365e-01\n",
      "  -8.16775761e-01  6.22759313e-02 -3.47461665e-01  5.71923216e-01\n",
      "  -1.69723332e-01  2.38073775e-01  5.14354300e-01  6.97565052e-01\n",
      "   1.32526075e-01  1.14113791e+00 -8.05554314e-01  1.27438279e+00\n",
      "   3.72598997e-01  3.66786061e-01  1.62876681e-01 -8.09098952e-02\n",
      "  -7.14654887e-02  4.31042700e-01  8.63548409e-01 -2.28953444e-01\n",
      "  -9.10509285e-02]\n",
      " [-1.55309580e+00 -1.15100351e+00  1.06527823e+00 -1.89827198e+00\n",
      "  -2.08975643e+00  8.80779659e-01 -3.39606815e-01 -3.61755959e-01\n",
      "  -8.31310786e-01  9.93348529e-01  1.40169311e+00 -1.49019354e+00\n",
      "   1.79571047e+00 -1.82023769e+00 -1.92734179e+00 -1.86141692e+00\n",
      "   1.40361103e+00 -1.81334106e+00  2.84268684e-01 -1.18185206e+00\n",
      "  -1.91006775e+00 -2.20365548e+00 -2.32469544e+00  3.44769104e-01\n",
      "   4.21215753e-01  1.38758598e+00 -6.77639740e-01 -1.14934384e+00\n",
      "  -7.12692477e-01]\n",
      " [-8.39251973e-01 -1.89889613e-01 -5.76410485e-02 -6.50942584e-01\n",
      "   5.84987912e-01  4.13435041e-01 -3.85312984e-01 -7.94652826e-02\n",
      "  -6.30916436e-01  1.56005528e-01  5.11370831e-01 -5.68263584e-01\n",
      "   5.89569227e-01 -4.37716877e-01 -7.49536268e-01 -8.11601924e-01\n",
      "   7.77387885e-01 -1.00997802e+00 -1.12320479e+00 -9.71933432e-01\n",
      "  -1.32524095e+00 -1.05002337e+00 -1.39256362e+00  8.69552569e-01\n",
      "  -3.15407467e-01 -1.40205381e-01 -8.14547581e-01  6.69711999e-02\n",
      "   2.99537096e-01]\n",
      " [ 3.02293717e-01 -1.22448651e+00 -1.18523143e-01 -7.86525164e-01\n",
      "  -1.09844555e+00 -1.77935677e+00  3.55639736e-01 -5.60964003e-01\n",
      "   1.12734660e+00 -9.58260047e-01  6.77738297e-01 -8.04021919e-01\n",
      "   1.21756977e+00  9.92918182e-01  1.11965819e-01 -7.99057895e-01\n",
      "   1.29978470e+00 -1.20458828e+00  1.13653238e+00 -1.30705644e+00\n",
      "  -6.06545261e-02  3.18146884e-01  1.01900332e+00 -1.83621454e-03\n",
      "  -6.52499281e-01 -9.75634135e-01  2.68144034e+00  5.75032021e-01\n",
      "   9.91626576e-01]]]\n",
      "[2024-07-05 16:29:21,887: INFO: 307610398: Data saved successfully!]\n",
      "[2024-07-05 16:29:21,888: INFO: 307610398: Preprocessor saved successfully!]\n",
      "[2024-07-05 16:29:21,889: INFO: 307610398: Data transformation completed successfully!]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config_manager = ConfigurationManager()\n",
    "    data_transformation_config = config_manager.get_data_transformation_config()\n",
    "    data_transformer = DataTransformation(config = data_transformation_config)\n",
    "    data_transformer.perform_data_transformation()\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to perform data transformation! Error: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "creditfault",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
