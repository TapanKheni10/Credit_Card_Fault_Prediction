{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tapankheni/Data_Science/Data Science Projects/Credit_Card_Fault_Prediction'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "\n",
    "@dataclass\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    x_train_data_path: List[str]\n",
    "    y_train_data_path: List[str]\n",
    "    x_val_data_path: List[str]\n",
    "    y_val_data_path: List[str]\n",
    "    model_name: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CreditCardFraudDetection.constants import PARAMS_YAML_FILE_PATH, CONFIG_YAML_FILE_PATH, SCHEMA_YAML_FILE_PATH\n",
    "from CreditCardFraudDetection.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self,\n",
    "                 params_yaml_file_path = PARAMS_YAML_FILE_PATH,\n",
    "                 config_yaml_file_path = CONFIG_YAML_FILE_PATH,\n",
    "                 schema_yaml_file_path = SCHEMA_YAML_FILE_PATH):\n",
    "        \n",
    "        self.params = read_yaml(params_yaml_file_path)\n",
    "        self.config = read_yaml(config_yaml_file_path)\n",
    "        self.schema = read_yaml(schema_yaml_file_path)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        config = self.config.model_trainer\n",
    "        params = self.params.model_selection\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        return ModelTrainerConfig(\n",
    "            root_dir = Path(config.root_dir),\n",
    "            x_train_data_path = config.x_train_data_path,\n",
    "            y_train_data_path = config.y_train_data_path,\n",
    "            x_val_data_path = config.x_val_data_path,\n",
    "            y_val_data_path = config.y_val_data_path,\n",
    "            model_name = config.model_name\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import joblib\n",
    "import os\n",
    "import time\n",
    "from CreditCardFraudDetection import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        self.config = config\n",
    "        self.models = {\n",
    "            'SVC': SVC(),\n",
    "            'RandomForestClassifier': RandomForestClassifier(),\n",
    "            'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "            'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "            'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
    "            'KNeighborsClassifier': KNeighborsClassifier()\n",
    "        }\n",
    "\n",
    "    def evaluate_model(self, true, predicted):\n",
    "\n",
    "        accuracy = accuracy_score(true, predicted)\n",
    "        precision = precision_score(true, predicted)\n",
    "        recall = recall_score(true, predicted)\n",
    "        f1 = f1_score(true, predicted)\n",
    "\n",
    "        return accuracy, precision, recall, f1\n",
    "\n",
    "    def model_training(self, X_train, y_train, X_test, y_test, models):\n",
    "        \n",
    "        model_performance = pd.DataFrame(columns=[\"accuracy\", \"precision\", \"recall\", \"f1_score\", \"training_time\", \"prediction_time\", \"total_time\"])\n",
    "\n",
    "        for i in range(len(models)):\n",
    "            start_time = time.time()\n",
    "            model = list(models.values())[i]\n",
    "            model.fit(X_train, y_train)\n",
    "            end_training = time.time()\n",
    "\n",
    "            y_pred = model.predict(X_test)\n",
    "            end_prediction = time.time()\n",
    "\n",
    "            accuracy, precision, recall, f1 = self.evaluate_model(y_test, y_pred)\n",
    "\n",
    "            model_performance.loc[list(models.keys())[i]] = [accuracy, precision, recall, f1, end_training-start_time, end_prediction-end_training, end_prediction-start_time]\n",
    "\n",
    "        if not os.path.exists(self.config.root_dir):\n",
    "            os.makedirs(self.config.root_dir)\n",
    "        \n",
    "        model_performance.to_json(os.path.join(self.config.root_dir, \"fraudulent_model_performance.json\"))\n",
    "        best_score = model_performance[\"recall\"].max()\n",
    "        best_model_name = model_performance[model_performance[\"recall\"] == best_score].index[0]\n",
    "\n",
    "        return best_score, best_model_name\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        logger.info(\"Training the model...\")\n",
    "        X_train_path = self.config.x_train_data_path[0]\n",
    "        y_train_path = self.config.y_train_data_path[0]\n",
    "        X_val_path = self.config.x_val_data_path[0]\n",
    "        y_val_path = self.config.y_val_data_path[0]\n",
    "\n",
    "        X_train = np.load(X_train_path)\n",
    "        y_train = np.load(y_train_path)\n",
    "        X_val = np.load(X_val_path)\n",
    "        y_val = np.load(y_val_path)\n",
    "        logger.info(\"Data loaded successfully\")\n",
    "\n",
    "        logger.info(f\"shape of X_train: {X_train.shape}\")\n",
    "        logger.info(f\"shape of y_train: {y_train.shape}\")\n",
    "        logger.info(f\"shape of X_val: {X_val.shape}\")\n",
    "        logger.info(f\"shape of y_val: {y_val.shape}\")\n",
    "\n",
    "        best_model_score, best_model_name = self.model_training(X_train, y_train, X_val, y_val, self.models)\n",
    "        logger.info(f\"Best model name: {best_model_name}\")\n",
    "        logger.info(f\"Best model score: {best_model_score}\")\n",
    "\n",
    "        model = self.models[best_model_name]\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        model_path = os.path.join(self.config.root_dir, self.config.model_name[0])\n",
    "        joblib.dump(model, model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-05 19:11:42,873: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-07-05 19:11:42,877: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-07-05 19:11:42,881: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2024-07-05 19:11:42,881: INFO: common: created directory at: artifacts]\n",
      "[2024-07-05 19:11:42,882: INFO: common: created directory at: artifacts/model_trainer]\n",
      "[2024-07-05 19:11:42,882: INFO: 364367102: Training the model...]\n",
      "[2024-07-05 19:11:42,911: INFO: 364367102: Data loaded successfully]\n",
      "[2024-07-05 19:11:42,920: INFO: 364367102: shape of X_train: (278628, 29)]\n",
      "[2024-07-05 19:11:42,921: INFO: 364367102: shape of y_train: (278628,)]\n",
      "[2024-07-05 19:11:42,926: INFO: 364367102: shape of X_val: (119413, 29)]\n",
      "[2024-07-05 19:11:42,927: INFO: 364367102: shape of y_val: (119413,)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tapankheni/Data_Science/Data Science Projects/Credit_Card_Fault_Prediction/creditfault/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-05 19:22:43,391: INFO: 364367102: Best model name: RandomForestClassifier]\n",
      "[2024-07-05 19:22:43,391: INFO: 364367102: Best model score: 1.0]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config_manager = ConfigurationManager()\n",
    "    model_trainer_config = config_manager.get_model_trainer_config()\n",
    "    model_trainer = ModelTrainer(config = model_trainer_config)\n",
    "    model_trainer.train()\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(e)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "creditfault",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
