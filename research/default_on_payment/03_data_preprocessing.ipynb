{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tapankheni/Data_Science/Data Science Projects/Credit_Card_Fault_Prediction'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: List[str]\n",
    "    preprocessed_data_path: List[str]\n",
    "    preprocessor_name: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CreditCardFraudDetection.constants import (PARAMS_YAML_FILE_PATH, CONFIG_YAML_FILE_PATH, SCHEMA_YAML_FILE_PATH)\n",
    "from CreditCardFraudDetection.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self,\n",
    "                 params_yaml_file_path = PARAMS_YAML_FILE_PATH,\n",
    "                 config_yaml_file_path = CONFIG_YAML_FILE_PATH,\n",
    "                 schema_yaml_file_path = SCHEMA_YAML_FILE_PATH):\n",
    "        \n",
    "        self.params = read_yaml(params_yaml_file_path)\n",
    "        self.config = read_yaml(config_yaml_file_path)\n",
    "        self.schema = read_yaml(schema_yaml_file_path)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            data_path = config.data_path,\n",
    "            preprocessed_data_path = config.preprocessed_data_path,\n",
    "            preprocessor_name = config.preprocessor_name\n",
    "        )\n",
    "\n",
    "        return data_transformation_config     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CreditCardFraudDetection import logger\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def split_data(self, data: pd.DataFrame, stratify_column: str):\n",
    "        train_data, test_data = train_test_split(data, stratify=data[stratify_column], test_size = 0.3, random_state = 42)\n",
    "        logger.info(\"Data split into train and test sets successfully!\")\n",
    "\n",
    "        X_train, y_train, X_test, y_test = train_data.drop(stratify_column, axis=1), train_data[stratify_column], test_data.drop(stratify_column, axis=1), test_data[stratify_column]\n",
    "        logger.info(\"Features and target variable retrieved successfully!\")\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def get_preprocessor_for_default_payment(self, data: pd.DataFrame) -> Pipeline:\n",
    "        cols_to_preprocess = list(data.columns)\n",
    "        \n",
    "        standardization = StandardScaler()\n",
    "\n",
    "        scaler_pipeline = Pipeline(\n",
    "            steps=[\n",
    "                (\"standardization\", standardization)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\"scaler_pipeline\", scaler_pipeline, cols_to_preprocess),\n",
    "            ],\n",
    "            remainder='passthrough'\n",
    "        )\n",
    "\n",
    "        preprocessor\n",
    "        logger.info(\"Preprocessor created successfully!\")\n",
    "\n",
    "        return preprocessor\n",
    "\n",
    "    def get_numerical_features(self, df) -> List[str]:\n",
    "        numerical_features = []\n",
    "\n",
    "        for col in df.columns:\n",
    "            if df[col].nunique() > 13:\n",
    "                numerical_features.append(col)\n",
    "            \n",
    "        return numerical_features \n",
    "    \n",
    "    def remove_outliers(self, df: pd.DataFrame, numerical_features: List[str]) -> pd.DataFrame:\n",
    "        for col in numerical_features:\n",
    "            q1 = df[col].quantile(0.25)\n",
    "            q3 = df[col].quantile(0.75)\n",
    "            \n",
    "            IQR = q3 - q1\n",
    "            lower_bound = q1 - 1.5 * IQR\n",
    "            upper_bound = q3 + 1.5 * IQR\n",
    "            \n",
    "            df[col] = df[col].clip(lower_bound, upper_bound)\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    def handle_undocumented_categories(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df[\"EDUCATION\"] = df[\"EDUCATION\"].map(lambda x : 4 if x in (5, 6, 0) else x)\n",
    "\n",
    "        df[\"MARRIAGE\"] = df[\"MARRIAGE\"].map(lambda x : 3 if x == 0 else x)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def handle_imbalance(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        logger.info(\"Handling imbalance in the data...\")\n",
    "        X = df.drop(columns=[\"default_status_next_month\"], axis=1)\n",
    "        y = df[\"default_status_next_month\"]\n",
    "\n",
    "        logger.info(f\"Distribution of the target feature before resampling: {y.value_counts()}\")\n",
    "\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X, y = smote.fit_resample(X, y)\n",
    "\n",
    "        logger.info(f\"Distribution of the target feature after resampling: {y.value_counts()}\")\n",
    "\n",
    "        df = X.copy()\n",
    "        df[\"default_status_next_month\"] = y\n",
    "\n",
    "        logger.info(f\"Shape of the data: {df.shape}\\n\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def perform_data_transformation_for_default_payment(self):\n",
    "        logger.info(\"Starting data transformation...\")\n",
    "\n",
    "        data_path = self.config.data_path[1]\n",
    "\n",
    "        data = pd.read_csv(data_path)\n",
    "        logger.info(f\"Data loaded successfully from {data_path}\")\n",
    "\n",
    "        data.rename(columns = {'PAY_0' : 'PAY_1',\n",
    "                               'default.payment.next.month' : 'default_status_next_month'}, inplace = True)\n",
    "        logger.info(\"Columns renamed successfully\")\n",
    "        logger.info(f\"Data columns: {data.columns}\")\n",
    "\n",
    "        numerical_features = self.get_numerical_features(data)\n",
    "        logger.info(f\"Numerical features: {numerical_features}\")\n",
    "\n",
    "        data = self.remove_outliers(data, numerical_features)\n",
    "        logger.info(\"Outliers removed successfully\")\n",
    "\n",
    "        data = data[data[\"BILL_AMT1\"] >= 0]\n",
    "        logger.info(\"Data with BILL_AMT1 >= 0, shape: {data.shape}\")\n",
    "\n",
    "        data = self.handle_undocumented_categories(data)\n",
    "        logger.info(f\"EDUCATION: \\n{data['EDUCATION'].value_counts()}\")\n",
    "        logger.info(f\"MARRIAGE: \\n{data['MARRIAGE'].value_counts()}\")\n",
    "        logger.info(\"Undocumented categories handled successfully\")\n",
    "\n",
    "        data.drop(columns=[\"BILL_AMT2\", \"BILL_AMT3\", \"BILL_AMT4\", \"BILL_AMT5\", \"BILL_AMT6\"], axis=1, inplace=True)\n",
    "        logger.info(\"Columns BILL_AMT2, BILL_AMT3, BILL_AMT4, BILL_AMT5, BILL_AMT6 dropped successfully\")\n",
    "        logger.info(f\"Data columns: {data.columns}\")\n",
    "\n",
    "        data = self.handle_imbalance(data)\n",
    "        logger.info(\"Imbalance handled successfully\")\n",
    "\n",
    "        X_train, X_test, y_train, y_test = self.split_data(data, \"default_status_next_month\")\n",
    "        logger.info(\"Data split into train and test sets successfully\")\n",
    "\n",
    "        preprocessor = self.get_preprocessor(X_train)\n",
    "        logger.info(\"Preprocessor retrieved successfully\")\n",
    "\n",
    "        logger.info(f\"Before transformation: \\n{X_train.head()}\")\n",
    "\n",
    "        X_train = preprocessor.fit_transform(X_train)\n",
    "        X_test = preprocessor.transform(X_test)\n",
    "\n",
    "        logger.info(f\"After transformation: \\n{X_train[:5]}\")\n",
    "\n",
    "        y_train = y_train.to_numpy()\n",
    "        y_test = y_test.to_numpy()\n",
    "\n",
    "        preprocessed_data_path = self.config.preprocessed_data_path[1]\n",
    "        if not os.path.exists(preprocessed_data_path):\n",
    "            os.makedirs(preprocessed_data_path, exist_ok=True)\n",
    "\n",
    "        np.save(os.path.join(preprocessed_data_path, \"X_train.npy\"), X_train)\n",
    "        np.save(os.path.join(preprocessed_data_path, \"X_test.npy\"), X_test)\n",
    "        np.save(os.path.join(preprocessed_data_path, \"y_train.npy\"), y_train)\n",
    "        np.save(os.path.join(preprocessed_data_path, \"y_test.npy\"), y_test)\n",
    "\n",
    "        logger.info(\"Data saved successfully!\")\n",
    "\n",
    "        joblib.dump(preprocessor, os.path.join(preprocessed_data_path, self.config.preprocessor_name))\n",
    "        logger.info(\"Preprocessor saved successfully!\")\n",
    "\n",
    "        logger.info(\"Data transformation completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-05 17:17:30,261: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-07-05 17:17:30,263: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-07-05 17:17:30,266: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2024-07-05 17:17:30,266: INFO: common: created directory at: artifacts]\n",
      "[2024-07-05 17:17:30,266: INFO: common: created directory at: artifacts/data_transformation]\n",
      "[2024-07-05 17:17:30,267: INFO: 1458035121: Starting data transformation...]\n",
      "[2024-07-05 17:17:30,295: INFO: 1458035121: Data loaded successfully from artifacts/data_ingestion/default.csv]\n",
      "[2024-07-05 17:17:30,296: INFO: 1458035121: Columns renamed successfully]\n",
      "[2024-07-05 17:17:30,296: INFO: 1458035121: Data columns: Index(['LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_1', 'PAY_2',\n",
      "       'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2',\n",
      "       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
      "       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6',\n",
      "       'default_status_next_month'],\n",
      "      dtype='object')]\n",
      "[2024-07-05 17:17:30,303: INFO: 1458035121: Numerical features: ['LIMIT_BAL', 'AGE', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']]\n",
      "[2024-07-05 17:17:30,321: INFO: 1458035121: Outliers removed successfully]\n",
      "[2024-07-05 17:17:30,324: INFO: 1458035121: Data with BILL_AMT1 >= 0, shape: {data.shape}]\n",
      "[2024-07-05 17:17:30,333: INFO: 1458035121: EDUCATION: \n",
      "EDUCATION\n",
      "2    13815\n",
      "1    10301\n",
      "3     4835\n",
      "4      459\n",
      "Name: count, dtype: int64]\n",
      "[2024-07-05 17:17:30,334: INFO: 1458035121: MARRIAGE: \n",
      "MARRIAGE\n",
      "2    15661\n",
      "1    13377\n",
      "3      372\n",
      "Name: count, dtype: int64]\n",
      "[2024-07-05 17:17:30,334: INFO: 1458035121: Undocumented categories handled successfully]\n",
      "[2024-07-05 17:17:30,336: INFO: 1458035121: Columns BILL_AMT2, BILL_AMT3, BILL_AMT4, BILL_AMT5, BILL_AMT6 dropped successfully]\n",
      "[2024-07-05 17:17:30,336: INFO: 1458035121: Data columns: Index(['LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_1', 'PAY_2',\n",
      "       'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'PAY_AMT1', 'PAY_AMT2',\n",
      "       'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6',\n",
      "       'default_status_next_month'],\n",
      "      dtype='object')]\n",
      "[2024-07-05 17:17:30,336: INFO: 1458035121: Handling imbalance in the data...]\n",
      "[2024-07-05 17:17:30,338: INFO: 1458035121: Distribution of the target feature before resampling: default_status_next_month\n",
      "0    22883\n",
      "1     6527\n",
      "Name: count, dtype: int64]\n",
      "[2024-07-05 17:17:30,565: INFO: 1458035121: Distribution of the target feature after resampling: default_status_next_month\n",
      "1    22883\n",
      "0    22883\n",
      "Name: count, dtype: int64]\n",
      "[2024-07-05 17:17:30,570: INFO: 1458035121: Shape of the data: (45766, 19)\n",
      "]\n",
      "[2024-07-05 17:17:30,572: INFO: 1458035121: Imbalance handled successfully]\n",
      "[2024-07-05 17:17:30,589: INFO: 1458035121: Data split into train and test sets successfully!]\n",
      "[2024-07-05 17:17:30,601: INFO: 1458035121: Features and target variable retrieved successfully!]\n",
      "[2024-07-05 17:17:30,608: INFO: 1458035121: Data split into train and test sets successfully]\n",
      "[2024-07-05 17:17:30,608: INFO: 1458035121: Preprocessor created successfully!]\n",
      "[2024-07-05 17:17:30,609: INFO: 1458035121: Preprocessor retrieved successfully]\n",
      "[2024-07-05 17:17:30,614: INFO: 1458035121: Before transformation: \n",
      "       LIMIT_BAL  SEX  EDUCATION  MARRIAGE        AGE  PAY_1  PAY_2  PAY_3  \\\n",
      "25459   150000.0    2          2         1  42.000000      0      0      0   \n",
      "36314    80000.0    1          2         1  37.576659      1      0      0   \n",
      "5689     50000.0    1          3         1  50.000000      2      0      0   \n",
      "5956     60000.0    2          3         1  40.000000      1     -1      0   \n",
      "27929    50000.0    2          2         1  41.000000      1      2      2   \n",
      "\n",
      "       PAY_4  PAY_5  PAY_6     BILL_AMT1      PAY_AMT1     PAY_AMT2  \\\n",
      "25459      0      2      0  15878.000000   1300.000000  1040.000000   \n",
      "36314     -1     -1     -2   5125.396469   1049.622924   670.580051   \n",
      "5689       0      0      0  48607.000000   2100.000000  1500.000000   \n",
      "5956       0     -1      0    749.000000  11015.000000  3000.000000   \n",
      "27929      2      0      0  23165.000000   2000.000000  2101.000000   \n",
      "\n",
      "          PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \n",
      "25459  1378.000000  1560.000     128.0     239.0  \n",
      "36314   670.580051     0.000       0.0       0.0  \n",
      "5689   1000.000000  1000.000    1000.0     700.0  \n",
      "5956   3020.000000  9589.125    1500.0    2000.0  \n",
      "27929     0.000000  2201.000    1000.0       0.0  ]\n",
      "[2024-07-05 17:17:30,634: INFO: 1458035121: After transformation: \n",
      "[[-0.01953135  0.99520441  0.34147668 -0.89289004  0.74300774 -0.15551582\n",
      "  -0.04913964 -0.00529856  0.05234633  1.81887942  0.12171958 -0.55769415\n",
      "  -0.56744588 -0.61752221 -0.42906664 -0.31407302 -0.81299747 -0.75952389]\n",
      " [-0.58437749 -1.0048187   0.34147668 -0.89289004  0.23446717  0.73701461\n",
      "  -0.04913964 -0.00529856 -0.78279659 -0.76243012 -1.58480494 -0.76924287\n",
      "  -0.64365116 -0.72961563 -0.65519432 -0.85458328 -0.857146   -0.84127673]\n",
      " [-0.82645441 -1.0048187   1.77711275 -0.89289004  1.66274791  1.62954504\n",
      "  -0.04913964 -0.00529856  0.05234633  0.09800639  0.12171958  0.08622225\n",
      "  -0.32395623 -0.477944   -0.54989482 -0.50810235 -0.51223564 -0.60183328]\n",
      " [-0.7457621   0.99520441  1.77711275 -0.89289004  0.5130727   0.73701461\n",
      "  -0.87637952 -0.00529856  0.05234633 -0.76243012  0.12171958 -0.8553449\n",
      "   2.38943155 -0.02279766  0.09580073  2.46786573 -0.33978047 -0.15715259]\n",
      " [-0.82645441  0.99520441  0.34147668 -0.89289004  0.62804022  0.73701461\n",
      "   1.60534011  1.65886535  1.72263217  0.09800639  0.12171958 -0.41432837\n",
      "  -0.35439243 -0.29558203 -0.86954608 -0.09197874 -0.51223564 -0.84127673]]]\n",
      "[2024-07-05 17:17:30,645: INFO: 1458035121: Data saved successfully!]\n",
      "[2024-07-05 17:17:30,646: INFO: 1458035121: Preprocessor saved successfully!]\n",
      "[2024-07-05 17:17:30,646: INFO: 1458035121: Data transformation completed successfully!]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config_manager = ConfigurationManager()\n",
    "    data_transformation_config = config_manager.get_data_transformation_config()\n",
    "    data_transformer = DataTransformation(config = data_transformation_config)\n",
    "    data_transformer.perform_data_transformation()\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to perform data transformation! Error: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "creditfault",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
